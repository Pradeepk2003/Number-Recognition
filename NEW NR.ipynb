{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f313fba5-cbb9-45f3-9aa5-817dfcee88fb",
   "metadata": {},
   "source": [
    "# **Number Recogniation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1edf7915-5966-49cf-984e-2eb7c83b0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f9564-d8f2-4c78-8905-6a484aa06443",
   "metadata": {},
   "source": [
    "**Loading Minist Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5904817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f7cf32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "input_shape =(28,28,1)\n",
    "y_test=to_categorical(y_test)\n",
    "y_train=to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5409108b-0b38-4447-9cc5-3ae4fd0ff3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfedfdc-bb21-40e7-8b4b-d5072f6f57fb",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c73678ab-824f-48ab-a1bc-ecef0346aa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train/255\n",
    "\n",
    "x_test = x_test/255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23472990-9fba-4c46-9eac-e54e3ead0007",
   "metadata": {},
   "source": [
    "**Model Enigineer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d385f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape = x_train.shape[1:]))\n",
    "model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer= keras.optimizers.Adadelta(), metrics=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1856b10-2115-4d09-94ef-5e1cc40d68e3",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ef2b6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 63s 133ms/step - loss: 2.3065 - val_loss: 2.2919\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 59s 126ms/step - loss: 2.2872 - val_loss: 2.2734\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 58s 123ms/step - loss: 2.2706 - val_loss: 2.2531\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 60s 129ms/step - loss: 2.2492 - val_loss: 2.2245\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 58s 123ms/step - loss: 2.2233 - val_loss: 2.1886\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 57s 120ms/step - loss: 2.1916 - val_loss: 2.1476\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 2.1568 - val_loss: 2.1016\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 58s 125ms/step - loss: 2.1186 - val_loss: 2.0507\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 57s 121ms/step - loss: 2.0786 - val_loss: 1.9952\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 57s 121ms/step - loss: 2.0350 - val_loss: 1.9362\n",
      "The model has successfully trained\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test ) )\n",
    "print(\"The model has successfully trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "859a3d6b-6fea-456f-9e42-5c83ef0e6e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3786\n",
      "Test accuracy: 0.3786050081253052\n"
     ]
    }
   ],
   "source": [
    "test_loss_and_test_acc = model.evaluate(x_test,y_test)\n",
    "acc=test_loss_and_test_acc \n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "074a996f-fe8c-4d01-bf78-577cc3899ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb89f3de-ae0f-4cec-84e3-f8a05a6a5886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abinj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved the model as mnist.h5 model successfully\n"
     ]
    }
   ],
   "source": [
    "model.save('digit_recognition_model.h5')\n",
    "print(\"saved the model as mnist.h5 model successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc06fc9",
   "metadata": {},
   "source": [
    "**Create GUI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af954b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2f7ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('digit_recognition_model.h5')\n",
    "\n",
    "# Load and preprocess a new image\n",
    "image_path = 'path_to_your_image.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (28, 28))\n",
    "image = image.reshape((1, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(image)\n",
    "predicted_digit = np.argmax(predictions)\n",
    "\n",
    "print('Predicted digit:', predicted_digit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
